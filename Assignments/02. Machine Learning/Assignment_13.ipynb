{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a102bc89",
   "metadata": {},
   "source": [
    "**1. Provide an example of the concepts of Prior, Posterior, and Likelihood.**  \n",
    "\n",
    "**Ans:** **Scenario: Medical Diagnosis for a Rare Disease**\n",
    "\n",
    "Imagine a rare disease that affects only 1 in 10,000 people. You're given a new patient with certain symptoms, and you want to determine the probability that they have this rare disease.\n",
    "\n",
    "1. **Prior Probability (Prior):** The prior probability is your initial belief about the likelihood of the patient having the rare disease before considering any specific information about their symptoms. Since the disease is rare (1 in 10,000), your prior probability might be quite low:\n",
    "    \n",
    "    Prior probability of having the disease = 0.0001 (or 0.01%)\n",
    "    \n",
    "2. **Likelihood (Likelihood):** The likelihood is the probability of observing the patient's symptoms given that they actually have the disease. Let's assume that for this disease, the likelihood of the symptoms occurring is relatively high (say, 0.8):\n",
    "    \n",
    "    Likelihood of symptoms given the disease = 0.8\n",
    "    \n",
    "3. **Posterior Probability (Posterior):** The posterior probability is the updated probability of the patient having the disease after considering their symptoms. This is calculated using Bayes' theorem, which incorporates both the prior probability and the likelihood.\n",
    "\n",
    "   **P(Disease∣Symptoms) = P(Symptoms) / P(Symptoms∣Disease)⋅P(Disease)​**\n",
    "    \n",
    "    Here, `P(Disease∣Symptoms)` is the posterior probability of having the disease given the symptoms, `P(Symptoms∣Disease)` is the likelihood, and `P(Disease)` is the prior probability.\n",
    "    \n",
    "    Let's calculate:   \n",
    "    P(Disease∣Symptoms) = 0.8 * 0.0001/ P(Symptoms)​\n",
    "    \n",
    "    Since we're assuming independence between symptoms for the sake of simplicity, `P(Symptoms)` would be the sum of the probability of having the disease and not having the disease but showing the symptoms.\n",
    "    \n",
    "    If the patient shows the symptoms, the posterior probability might 0.08%\n",
    "      \n",
    "**2. What role does Bayes' theorem play in the concept learning principle?**  \n",
    "\n",
    "**Ans:** Bayes' theorem plays a significant role in the concept learning principle, particularly in the context of probabilistic reasoning and making informed decisions based on evidence and prior knowledge. The concept learning principle involves learning and categorizing objects, events, or data into different classes or categories.\n",
    "\n",
    "Bayes' theorem provides a framework for updating our beliefs or probabilities about different hypotheses or classes as new evidence becomes available. It helps us make decisions by combining prior knowledge with observed data. In the context of concept learning, Bayes' theorem enables us to refine our understanding of the likelihood of different categories given observed features.\n",
    "\n",
    "Here's how Bayes' theorem is relevant to the concept learning principle:\n",
    "\n",
    "1. **Incorporating Prior Knowledge:** Bayes' theorem allows us to incorporate prior knowledge or initial beliefs about the likelihood of different classes. This is important because it provides a starting point for understanding the relative probability of different categories before observing any evidence.\n",
    "    \n",
    "2. **Updating Probabilities:** As new evidence or features are observed, Bayes' theorem enables us to update the probabilities of different classes. The likelihood term in Bayes' theorem represents how well the observed evidence aligns with each class. This updating process helps us revise our understanding of the probabilities of different classes based on the available data.\n",
    "    \n",
    "3. **Optimal Decision Making:** By using Bayes' theorem, we can make optimal decisions about which class or category an object or data point belongs to. The theorem helps us calculate the posterior probability of each class given the observed features, allowing us to choose the class with the highest posterior probability as our decision.\n",
    "\n",
    "**3. Offer an example of how the Nave Bayes classifier is used in real life.** \n",
    "\n",
    "**Ans:** **Example: Spam Email Filtering**\n",
    "\n",
    "**Problem:** You run an email service, and you want to automatically filter out spam emails from your users' inboxes to improve their experience.\n",
    "\n",
    "**Solution:** You decide to use the Naïve Bayes classifier for spam email filtering due to its effectiveness and efficiency.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Data Collection:** You gather a large dataset of labeled emails, where each email is categorized as either \"spam\" or \"not spam\" (ham).\n",
    "    \n",
    "2. **Feature Extraction:** You preprocess the emails and extract features, which could include the presence of specific words, frequency of certain phrases, length of the email, and more. Each feature is represented as a binary or numeric value.\n",
    "    \n",
    "3. **Training:** You use the labeled data to train the Naïve Bayes classifier. For each category (spam and ham), the classifier calculates the likelihood of each feature occurring given that category.\n",
    "    \n",
    "4. **Classification:** When a new email arrives, the Naïve Bayes classifier uses the calculated likelihoods to estimate the probability of the email being spam or ham for both categories.\n",
    "    \n",
    "5. **Decision:** The classifier assigns the email to the category with the higher probability. If the probability of being spam is higher, the email is flagged as spam and moved to a separate folder.\n",
    "    \n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- **Efficiency:** Naïve Bayes classifiers are computationally efficient, making them suitable for processing a large volume of emails in real time.\n",
    "    \n",
    "- **Adaptability:** The classifier can learn and adapt to new types of spam over time as new data is collected.\n",
    "    \n",
    "- **Effectiveness:** Despite its simplifying assumptions, Naïve Bayes often performs well in distinguishing spam from legitimate emails due to the presence of certain keywords or patterns associated with spam.\n",
    "\n",
    "**4. Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about doing it?**  \n",
    "\n",
    "**Ans:** Yes, the Naïve Bayes classifier can be used on continuous numeric data. While it is commonly associated with categorical data and text classification, Naïve Bayes can also handle continuous data by applying probability density functions to estimate the likelihood of observing continuous features given a class.\n",
    "\n",
    "Here's how you can use the Naïve Bayes classifier for continuous numeric data:\n",
    "\n",
    "1. **Choose Probability Density Functions (PDFs):** For each class, you need to assume or determine the type of probability distribution that fits the continuous features. Common choices are the Gaussian (normal) distribution for symmetric data, the exponential distribution for non-negative data, or other appropriate distributions based on the nature of the data.\n",
    "    \n",
    "2. **Estimate Parameters:** For each class, you need to estimate the parameters of the chosen probability distribution. For example, for the Gaussian distribution, you need to estimate the mean and variance for each feature within each class.\n",
    "    \n",
    "3. **Calculate Likelihoods:** Given a new data point with continuous features, calculate the likelihood of observing those features under each class's distribution. This involves plugging the feature values into the PDFs and obtaining the corresponding probabilities.\n",
    "    \n",
    "4. **Apply Bayes' Theorem:** Combine the likelihoods with the prior probabilities of each class and calculate the posterior probabilities using Bayes' theorem.\n",
    "    \n",
    "5. **Make a Decision:** Assign the new data point to the class with the highest posterior probability.\n",
    "\n",
    "It's important to note that using the Naïve Bayes classifier for continuous data assumes that the features are independent given the class, just like with categorical data. However, this assumption might not hold well for highly correlated continuous features.\n",
    "\n",
    "While Naïve Bayes can be used for continuous data, its performance might not be as strong as more sophisticated models specifically designed for continuous data, like Gaussian Naïve Bayes for continuous Gaussian-distributed features, or other machine learning algorithms such as linear regression, decision trees, or support vector machines. It's a good idea to compare the performance of Naïve Bayes with other methods on your specific dataset to determine the most suitable approach.\n",
    "\n",
    "**5. What are Bayesian Belief Networks, and how do they work? What are their applications? Are they capable of resolving a wide range of issues?**  \n",
    "\n",
    "**Ans:** **Bayesian Belief Networks (BBNs)**, also known as Bayesian Networks or Bayes Nets, are graphical models that represent and reason about uncertainty and probabilistic relationships between variables. They are used to model complex systems where variables interact and influence each other in uncertain ways. BBNs are based on probability theory and graph theory, making them valuable for decision-making, risk assessment, and prediction in various fields.\n",
    "\n",
    "**How BBNs Work:**\n",
    "\n",
    "1. **Graphical Representation:** BBNs use a graph structure to represent variables as nodes and probabilistic relationships as directed edges. Each node corresponds to a variable, and edges indicate probabilistic dependencies between variables.\n",
    "    \n",
    "2. **Conditional Probability Tables (CPTs):** BBNs utilize Conditional Probability Tables that quantify how each variable's state depends on the states of its parent nodes. These tables encode the conditional probabilities for each possible combination of parent states.\n",
    "    \n",
    "3. **Inference:** Given some evidence about certain variables, BBNs use Bayes' theorem to calculate posterior probabilities for other variables. Inference involves propagating probabilities through the network to compute the most likely states for unobserved variables.\n",
    "    \n",
    "\n",
    "**Applications of BBNs:**\n",
    "\n",
    "1. **Diagnosis and Medical Decision-Making:** BBNs are used in medical diagnosis by modeling symptoms, test results, and diseases. They help doctors make informed decisions based on available evidence.\n",
    "    \n",
    "2. **Risk Assessment and Management:** BBNs are employed in assessing and managing risks in areas like finance, engineering, and safety. They provide a framework to model uncertain events and make decisions under uncertainty.\n",
    "    \n",
    "3. **Predictive Modeling:** BBNs can predict outcomes based on observed evidence. In finance, they can predict market trends; in environmental science, they can predict the impact of climate change.\n",
    "    \n",
    "4. **Causal Inference:** BBNs can identify causal relationships between variables and help explore cause-and-effect scenarios.\n",
    "    \n",
    "5. **Natural Language Processing:** BBNs assist in tasks like sentiment analysis, language understanding, and machine translation by modeling relationships between words and concepts.\n",
    "    \n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "While BBNs are versatile and powerful, they have limitations:\n",
    "\n",
    "- **Complexity:** Creating BBNs requires domain expertise and data to estimate probabilities accurately.\n",
    "- **Data Dependency:** Accurate probabilities depend on accurate data. Limited or biased data can lead to inaccurate inferences.\n",
    "- **Size and Complexity:** Handling large and complex networks can become computationally intensive.\n",
    "- **Assumptions:** BBNs assume conditional independence of variables given their parents, which might not always hold\n",
    "\n",
    "**6. Passengers are checked in an airport screening system to see if there is an intruder. Let I be the random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98 and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered, implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) = 0.00001. What are the chances that an alarm would be triggered when an individual is actually an intruder?**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34804c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that an alarm is triggered when an individual is an intruder: 0.009704988165856267\n"
     ]
    }
   ],
   "source": [
    "# Given values\n",
    "P_A_given_I_1 = 0.98\n",
    "P_A_given_I_0 = 0.001\n",
    "P_I_1 = 0.00001\n",
    "P_I_0 = 1 - P_I_1\n",
    "\n",
    "# Calculate P(A = 1)\n",
    "P_A_1 = P_A_given_I_1 * P_I_1 + P_A_given_I_0 * P_I_0\n",
    "\n",
    "# Calculate P(I = 1|A = 1)\n",
    "P_I_1_given_A_1 = (P_A_given_I_1 * P_I_1) / P_A_1\n",
    "\n",
    "print(f\"Probability that an alarm is triggered when an individual is an intruder: {P_I_1_given_A_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b2cc4",
   "metadata": {},
   "source": [
    "**7. An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune (random variable D).**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640ea5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood that a person who tests positive is actually immune: 0.6597222222222222\n"
     ]
    }
   ],
   "source": [
    "# Given values\n",
    "P_T_given_D_1 = 0.95\n",
    "P_D_1 = 0.02\n",
    "P_D_0 = 1 - P_D_1\n",
    "P_T_given_D_0 = 0.01\n",
    "\n",
    "# Calculate P(T = 1)\n",
    "P_T_1 = P_T_given_D_1 * P_D_1 + P_T_given_D_0 * P_D_0\n",
    "\n",
    "# Calculate P(D = 1|T = 1)\n",
    "P_D_1_given_T_1 = (P_T_given_D_1 * P_D_1) / P_T_1\n",
    "\n",
    "print(f\"Likelihood that a person who tests positive is actually immune: {P_D_1_given_T_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e759c4",
   "metadata": {},
   "source": [
    "**8. In order to prepare for the test, a student knows that there will be one question in the exam that is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and 50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10 type B problems, and 6 of 10 type C problems.** \n",
    "\n",
    "**Ans:**\n",
    "Given:\n",
    "\n",
    "- Probability of getting A: 30%\n",
    "- Probability of getting B: 20%\n",
    "- Probability of getting C: 50%\n",
    "- Number of type A problems solved: 9 out of 10\n",
    "- Number of type B problems solved: 2 out of 10\n",
    "- Number of type C problems solved: 6 out of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541415a6",
   "metadata": {},
   "source": [
    "**8.1. What is the likelihood that the student can solve the exam problem?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63c19d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood that the student can solve the exam problem: 0.6100000000000001\n"
     ]
    }
   ],
   "source": [
    "# Given values\n",
    "P_A = 0.30\n",
    "P_B = 0.20\n",
    "P_C = 0.50\n",
    "\n",
    "# Number of problems solved for each type\n",
    "n_solved_A = 9\n",
    "n_solved_B = 2\n",
    "n_solved_C = 6\n",
    "\n",
    "# Likelihood of solving a problem given its form\n",
    "P_solve_given_A = n_solved_A / 10\n",
    "P_solve_given_B = n_solved_B / 10\n",
    "P_solve_given_C = n_solved_C / 10\n",
    "\n",
    "# Likelihood that the student can solve the exam problem\n",
    "P_solve_exam = P_A * P_solve_given_A + P_B * P_solve_given_B + P_C * P_solve_given_C\n",
    "\n",
    "print(f\"Likelihood that the student can solve the exam problem: {P_solve_exam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9783790",
   "metadata": {},
   "source": [
    "**8.2. Given the student's solution, what is the likelihood that the problem was of form A?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "528ce96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood that the problem was of form A given the student's solution: 0.44262295081967207\n"
     ]
    }
   ],
   "source": [
    "# Likelihood of solving any problem\n",
    "P_solve_any = P_A * P_solve_given_A + P_B * P_solve_given_B + P_C * P_solve_given_C\n",
    "\n",
    "# Likelihood of solving the problem given its form A\n",
    "P_solve_given_A = n_solved_A / 10\n",
    "\n",
    "# Likelihood that the problem was of form A given the student solved it\n",
    "P_A_given_solved = (P_solve_given_A * P_A) / P_solve_any\n",
    "\n",
    "print(f\"Likelihood that the problem was of form A given the student's solution: {P_A_given_solved}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0cb0c",
   "metadata": {},
   "source": [
    "**9. A bank installs a CCTV system to track and photograph incoming customers. Despite the constant influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the camera can take a false photograph with a 10% chance of detecting movement from other objects.**  \n",
    "\n",
    "**9.1. How many customers come into the bank on a daily basis (10 hours)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c4f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers coming into the bank on a daily basis: 6.0\n"
     ]
    }
   ],
   "source": [
    "average_customers_per_interval = 0.05\n",
    "number_of_intervals_per_day = 120\n",
    "\n",
    "number_of_customers_per_day = average_customers_per_interval * number_of_intervals_per_day\n",
    "print(f\"Number of customers coming into the bank on a daily basis: {number_of_customers_per_day}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0931230d",
   "metadata": {},
   "source": [
    "**9.2. On a daily basis, how many fake photographs (photographs taken when there is no customer) and how many missed photographs (photographs taken when there is a customer) are there?**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c0e1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fake photographs on a daily basis: 12.0\n",
      "Number of missed photographs on a daily basis: 0.06000000000000005\n"
     ]
    }
   ],
   "source": [
    "probability_fake_photograph = 0.10\n",
    "probability_missed_photograph = 1 - 0.99  # Probability of not detecting a customer when there is one\n",
    "\n",
    "number_of_fake_photographs_per_day = probability_fake_photograph * number_of_intervals_per_day\n",
    "number_of_missed_photographs_per_day = probability_missed_photograph * number_of_customers_per_day\n",
    "\n",
    "print(f\"Number of fake photographs on a daily basis: {number_of_fake_photographs_per_day}\")\n",
    "print(f\"Number of missed photographs on a daily basis: {number_of_missed_photographs_per_day}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce042928",
   "metadata": {},
   "source": [
    "**10. Create the conditional probability table associated with the node Won Toss in the Bayesian Belief network to represent the conditional independence assumptions of the Nave Bayes classifier for the match winning prediction problem in Section 6.4.4.**  \n",
    "**Ans:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

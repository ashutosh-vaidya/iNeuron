{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b45a03",
   "metadata": {},
   "source": [
    "**1. What is the estimated depth of a Decision Tree trained (unrestricted) on a one million instance training set?**\n",
    "\n",
    "**Ans:** The estimated depth of a Decision Tree trained on a one million instance training set without any restrictions can vary widely based on factors such as the complexity of the data, the number of features, and the desired level of granularity. In practice, without any constraints, the depth of such a tree could potentially become very deep, possibly reaching hundreds or even thousands of levels. However, this could result in overfitting and poor generalization to new data.\n",
    "\n",
    "To prevent overfitting and to achieve better generalization, it's common to set constraints on the tree's depth, the minimum number of samples per leaf, or other hyperparameters during the training process. This helps strike a balance between capturing important patterns in the data and preventing the model from becoming too complex and sensitive to noise.\n",
    "\n",
    "**2. Is the Gini impurity of a node usually lower or higher than that of its parent? Is it always lower/greater, or is it usually lower/greater?**\n",
    "\n",
    "**Ans:** The Gini impurity of a node in a decision tree is usually lower than that of its parent. The Gini impurity measures the level of impurity or disorder in a set of data points. When a node is split into child nodes, the goal is to reduce impurity by creating subsets that are more homogeneous in terms of class distribution. This typically results in a lower Gini impurity in the child nodes compared to the parent node.\n",
    "\n",
    "However, it's important to note that while the general trend is to reduce Gini impurity with splits, there could be cases where a specific split might slightly increase the impurity of a node due to the overall reduction in impurity across the entire tree structure. In practice, decision tree algorithms evaluate multiple possible splits and select the one that results in the greatest reduction in impurity.\n",
    "\n",
    "**3. Explain if its a good idea to reduce max depth if a Decision Tree is overfitting the training set?**\n",
    "\n",
    "**Ans:** \n",
    "Reducing the max depth of a Decision Tree is a common strategy to mitigate overfitting on the training set. Overfitting occurs when the tree becomes too complex, capturing noise and specificities of the training data that do not generalize well to new, unseen data. Here's why reducing max depth can be a good idea:\n",
    "\n",
    "1. Simplifying Model Complexity: Limiting the max depth restricts the depth of the tree, preventing it from growing too deep and fitting the training data too closely. This results in a simpler and more general model.\n",
    "\n",
    "2. Improved Generalization: A shallower tree with limited depth is less likely to capture noise in the training data, leading to better generalization performance on unseen data.\n",
    "\n",
    "3. Reduced Variance: A deep tree tends to have high variance, meaning it's sensitive to small fluctuations in the training data. Reducing max depth reduces this variance, making the model more stable and reliable.\n",
    "\n",
    "3. Interpretability: Shallow trees are easier to interpret and visualize, as the decision-making process is more straightforward and involves fewer features and rules.\n",
    "\n",
    "However, it's important to find the right balance. If the max depth is set too low, the model might suffer from underfitting, where it fails to capture important patterns in the data. Therefore, a careful consideration of model complexity and performance on validation or test data is necessary when adjusting the max depth to combat overfitting. Cross-validation and monitoring the trade-off between bias and variance can help determine an optimal value for the max depth parameter.\n",
    "\n",
    "**4. Explain if its a  good idea to try scaling the input features if a Decision Tree underfits the training set?**\n",
    "\n",
    "**Ans:** Scaling input features is not typically recommended as a solution to address underfitting in a Decision Tree model. Decision Trees are generally robust to the scale of input features due to their nature of making binary splits based on feature thresholds. Underfitting in a Decision Tree is often related to the tree's complexity rather than the scaling of features. Here's why scaling might not be an effective solution:\n",
    "\n",
    "1. Tree Structure: Decision Trees split data based on feature thresholds without considering absolute feature values. Scaling features won't change the inherent structure of the tree and its ability to capture patterns.\n",
    "\n",
    "2. Overfitting Risk: Scaling might not directly impact underfitting, and it could even introduce overfitting if features are scaled to a range where the tree becomes sensitive to minor fluctuations.\n",
    "\n",
    "3. Complexity Adjustment: Addressing underfitting in a Decision Tree typically involves adjusting hyperparameters that control tree complexity, such as increasing max depth, adjusting the minimum samples per leaf, or employing ensemble techniques like Random Forest.\n",
    "\n",
    "4. Feature Engineering: Rather than scaling, feature engineering techniques like adding relevant features, creating interactions, or using polynomial features might be more effective in capturing complex relationships.\n",
    "\n",
    "5. Data Exploration: It's important to analyze the data and its distribution to understand why underfitting is occurring. Scaling might not be the root cause.\n",
    "\n",
    "If a Decision Tree is underfitting, it's advisable to explore adjustments to the model's hyperparameters, data preprocessing, or even consider switching to more complex models if the underlying patterns demand it.\n",
    "\n",
    "**5. How much time will it take to train another Decision Tree on a training set of 10 million instances if it takes an hour to train a Decision Tree on a training set with 1 million instances?**\n",
    "\n",
    "**Ans:** The time taken to train a machine learning model like a Decision Tree is not always directly proportional to the size of the training set. While it's logical to assume that training a model on a larger dataset will take more time, the exact relationship can depend on various factors such as the algorithm's complexity, hardware resources, parallel processing, and optimization techniques.\n",
    "\n",
    "Assuming that all other conditions remain the same, a rough estimate would be that training a Decision Tree on a training set with 10 million instances could take around 10 hours. However, this is a simplified estimate and the actual time could vary based on the factors mentioned earlier. If you have access to more powerful hardware or efficient parallel processing techniques, the training time might be reduced.\n",
    "\n",
    "**6. Will setting presort=True speed up training if your training set has 100,000 instances?**\n",
    "\n",
    "**Ans:** In the context of the DecisionTreeClassifier or DecisionTreeRegressor in scikit-learn, the presort parameter controls whether the data should be presorted to speed up the fitting process. However, the impact of setting presort=True depends on the size of the dataset.\n",
    "\n",
    "For smaller datasets like the one with 100,000 instances, setting presort=True might actually slow down the training process. The reason is that presorting the data involves an additional time-consuming step before training starts. This step is only beneficial for relatively large datasets where the overhead of presorting is offset by the faster tree construction process that follows.\n",
    "\n",
    "For smaller datasets, the overhead of presorting can outweigh the benefits, resulting in longer overall training times. Therefore, it's generally recommended to keep presort=False for datasets of this size.\n",
    "\n",
    "However, the best approach is to experiment with both settings (presort=True and presort=False) and measure the actual training times to determine which configuration is more efficient for your specific dataset and hardware resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6df4f8",
   "metadata": {},
   "source": [
    "**7. Follow these steps to train and fine-tune a Decision Tree for the moons dataset:**\n",
    "\n",
    "**a. To build a moons dataset, use make moons(n samples=10000, noise=0.4).**\n",
    "\n",
    "**b. Divide the dataset into a training and a test collection with train test split().**\n",
    "\n",
    "**c. To find good hyperparameters values for a DecisionTreeClassifier, use grid search with cross-validation (with the GridSearchCV class). Try different values for max leaf nodes.**\n",
    "\n",
    "**d. Use these hyperparameters to train the model on the entire training set, and then assess its output on the test set. You can achieve an accuracy of 85 to 87 percent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a38423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 87.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step a: Create the moons dataset\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
    "\n",
    "# Step b: Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step c: Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'max_leaf_nodes': [None, 10, 20, 30, 40]}\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(tree_clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_max_leaf_nodes = grid_search.best_params_['max_leaf_nodes']\n",
    "\n",
    "# Step d: Train the model with the best hyperparameters on the entire training set\n",
    "final_tree_clf = DecisionTreeClassifier(max_leaf_nodes=best_max_leaf_nodes, random_state=42)\n",
    "final_tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = final_tree_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy on the test set: {accuracy * 100} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38396322",
   "metadata": {},
   "source": [
    "**8. Follow these steps to grow a forest:**\n",
    "\n",
    "**a. Using the same method as before, create 1,000 subsets of the training set, each containing 100 instances chosen at random. You can do this with Scikit-ShuffleSplit Learn's class.**\n",
    "\n",
    "**b. Using the best hyperparameter values found in the previous exercise, train one Decision Tree on each subset. On the test collection, evaluate these 1,000 Decision Trees. These Decision Trees would likely perform worse than the first Decision Tree, achieving only around 80% accuracy, since they were trained on smaller sets.**\n",
    "\n",
    "**c. Now the magic begins. Create 1,000 Decision Tree predictions for each test set case, and keep only the most common prediction (you can do this with SciPy's mode() function). Over the test collection, this method gives you majority-vote predictions.**\n",
    "\n",
    "**d. On the test range, evaluate these predictions: you should achieve a slightly higher accuracy than the first model (approx 0.5 to 1.5 percent higher). You've successfully learned a Random Forest classifier!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e7beda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Random Forest: 0.869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91895\\AppData\\Local\\Temp\\ipykernel_3536\\1526612531.py:24: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  forest_majority_votes = mode(np.array(forest_predictions), axis=0).mode[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step a: Create 1,000 subsets of the training set\n",
    "n_subsets = 1000\n",
    "subset_size = 100\n",
    "subsets = []\n",
    "\n",
    "shuffle_split = ShuffleSplit(n_splits=n_subsets, test_size=subset_size, random_state=42)\n",
    "for train_index, _ in shuffle_split.split(X_train):\n",
    "    subsets.append(train_index)\n",
    "\n",
    "# Step b: Train and evaluate 1,000 Decision Trees\n",
    "forest_predictions = []\n",
    "for subset in subsets:\n",
    "    tree_clf = DecisionTreeClassifier(max_leaf_nodes=best_max_leaf_nodes, random_state=42)\n",
    "    tree_clf.fit(X_train[subset], y_train[subset])\n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    forest_predictions.append(y_pred)\n",
    "\n",
    "# Step c: Perform majority voting\n",
    "forest_majority_votes = mode(np.array(forest_predictions), axis=0).mode[0]\n",
    "\n",
    "# Step d: Evaluate the Random Forest on the test set\n",
    "accuracy_forest = accuracy_score(y_test, forest_majority_votes)\n",
    "\n",
    "print(f\"Accuracy of the Random Forest: {accuracy_forest}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
